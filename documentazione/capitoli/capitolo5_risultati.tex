\chapter{Risultati Sperimentali}

\section{Introduzione}
In questo capitolo vengono presentati e confrontati i risultati sperimentali delle tre configurazioni principali: DQN Baseline, DQN+Helper e HeRoN (DQN+Helper+Reviewer). L'obiettivo è valutare l'impatto dell'integrazione LLM e Reviewer sulle performance dell'agente.

\section{Setup Sperimentale}
\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\rowcolor{gray!20}
\textbf{Parametro} & \textbf{Valore} \\
\hline
Episodi totali & 300 \\
\hline
Max steps per episodio & 1000 \\
\hline
Learning rate DQN & 0.0001 \\
\hline
Batch size & 64 \\
\hline
Gamma ($\gamma$) & 0.99 \\
\hline
Epsilon iniziale & 1.0 \\
\hline
Epsilon finale & 0.05 \\
\hline
Epsilon decay & 300 episodi \\
\hline
Replay buffer size & 5,000 \\
\hline
Alpha prioritization & 0.6 \\
\hline
Beta IS weight & 0.4 $\rightarrow$ 1.0 \\
\hline
Threshold iniziale & 1.0 \\
\hline
Threshold decay & 0.01 per episodio \\
\hline
LLM cutoff & Episodio 100 \\
\hline
\end{tabular}
\caption{Parametri di training}
\end{table}

\section{Configurazioni Testate}
\begin{itemize}
	\item \textbf{DQN Baseline}: Solo Deep Q-Network
	\item \textbf{DQN + Helper}: DQN + Helper senza Reviewer
	\item \textbf{HeRoN}: DQN + Helper + Reviewer
\end{itemize}

\section{Confronto tra Configurazioni}

% --- TABELLE METRICHE PRINCIPALI ---
\subsection{DQN Baseline}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metriche} & \textbf{Valore} & \textbf{Note} \\
\hline
Achievement medio & 2.74 & std 1.19, max 6 \\
\hline
Coverage & 36.4\% & 8/22 \\
\hline
Reward medio & 7.99 & ultimi 100 episodi \\
\hline
\end{tabular}
\caption{Metriche principali DQN Baseline}
\end{table}

\textbf{Osservazioni}: DQN Baseline sblocca solo achievement semplici e mostra performance limitate su reward e copertura.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/plots_dqn_BASE/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica DQN Baseline.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_BASE/achievement_heatmap.png}
\caption{Heatmap achievement DQN Baseline.}
\end{figure}

% Curve di apprendimento DQN Baseline
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_BASE/achievement_curves/learning_curve_collect_wood.png}
\caption{Curve di apprendimento collect\_wood - DQN Baseline.}
\end{figure}
% ...aggiungi altre curve se necessario...

\subsection{DQN+Helper}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metriche} & \textbf{Valore} & \textbf{Note} \\
\hline
Achievement medio & 2.67 & std 1.10, max 6 \\
\hline
Coverage & 50.0\% & 11/22 \\
\hline
Reward medio & 7.86 & ultimi 100 episodi \\
\hline
\end{tabular}
\caption{Metriche principali DQN+Helper}
\end{table}

\textbf{Osservazioni}: DQN+Helper migliora la copertura degli achievement, sbloccando anche obiettivi di pianificazione e crafting, ma la consistenza e l'efficienza rimangono inferiori rispetto a HeRoN.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/plots_dqn_helper/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica DQN+Helper.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_heatmap.png}
\caption{Heatmap achievement DQN+Helper.}
\end{figure}

% Curve di apprendimento DQN+Helper
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/collect_wood.png}
\caption{Curve di apprendimento collect\_wood - DQN+Helper.}
\end{figure}
% ...aggiungi altre curve se necessario...

\subsection{HeRoN}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metriche} & \textbf{Valore} & \textbf{Note} \\
\hline
Achievement medio & 2.8 & std 1.15, max 5 \\
\hline
Coverage & 41.0\% & 9/22 \\
\hline
Reward medio & 8.33 & ultimi 100 episodi \\
\hline
\end{tabular}
\caption{Metriche principali HeRoN}
\end{table}

\textbf{Osservazioni}: HeRoN mantiene una distribuzione stabile degli achievement, pianifica meglio e converge più rapidamente. Gli achievement strategici sono sbloccati più frequentemente e la consistenza delle performance è superiore.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/heron/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica HeRoN.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/heron/achievement_heatmap.png}
\caption{Heatmap achievement HeRoN.}
\end{figure}

% Curve di apprendimento HeRoN
\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{immagini/heron/achievement_curves/collect_wood.png}
\caption{Curve di apprendimento collect\_wood - HeRoN.}
\end{figure}
% ...aggiungi altre curve se necessario...

% Confronti diretti tra configurazioni (minipage)
\subsection{Confronti Diretti}
\begin{figure}[H]
\centering
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{immagini/heron/achievement_curves/collect_wood.png}
\caption*{HeRoN}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{immagini/plots_dqn_BASE/achievement_curves/learning_curve_collect_wood.png}
\caption*{DQN Baseline}
\end{minipage}
\caption{Confronto curve di apprendimento per collect\_wood.}
\end{figure}
% ...aggiungi altri confronti minipage se necessario...

% --- TABELLA COVERAGE ---
\subsection{Coverage Achievement}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Coverage} & \textbf{Percentuale} \\
\hline
DQN Baseline & 8 / 22 & 36.4\% \\
\hline
DQN + Helper & 11 / 22 & 50.0\% \\
\hline
HeRoN Completo & 9 / 22 & 41.0\% \\
\hline
\end{tabular}
\caption{Coverage degli achievement}
\end{table}

\textbf{Nota sulla coverage DQN+Helper vs HeRoN:}

Nonostante DQN+Helper raggiunga una coverage più alta (11/22 achievement unici) rispetto a HeRoN (9/22), l'analisi dettagliata mostra che i due achievement "extra" vengono sbloccati una sola volta durante il training, senza essere consolidati o ripetuti. 

Questo risultato è dovuto principalmente all'esplorazione casuale favorita dall'Helper, che porta il sistema a visitare più aree del gioco ma senza sviluppare strategie stabili. Al contrario, HeRoN, grazie all'integrazione del Reviewer, privilegia la consistenza e l'ottimizzazione del reward, raggiungendo meno achievement unici ma in modo più frequente e robusto. 

Pertanto, la maggiore coverage di DQN+Helper non rappresenta una vera superiorità strategica, ma solo una variabilità episodica non ripetibile.

% --- TABELLA REWARD CUMULATIVO ---
\subsection{Reward Cumulativo}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Media} & \textbf{Std Dev} \\
\hline
DQN Baseline & 7.99 & 2.62 \\
\hline
DQN + Helper & 7.86 & 2.31 \\
\hline
HeRoN Completo & 8.33 & 2.40 \\
\hline
\end{tabular}
\caption{Reward cumulativo per episodio (ultimi 100 episodi)}
\end{table}

\subsection{Analisi Qualitativa}
\textbf{Osservazioni comparative}:
\begin{itemize}
	\item DQN+Helper sblocca più achievement rispetto al DQN base, ma molti di questi vengono sbloccati solo una volta e non consolidati.
	\item HeRoN mantiene la distribuzione dei reward più stabile e una maggiore efficienza temporale, anche se la copertura degli achievement avanzati rimane limitata.
	\item La varianza tra le configurazioni è simile, ma HeRoN mostra una maggiore consistenza nelle performance.
	\item DQN+Helper e HeRoN convergono più rapidamente rispetto al DQN base, ma solo HeRoN mantiene stabilità e pianificazione strategica.
	\item In tutti i confronti, HeRoN si conferma superiore per efficienza, stabilità e capacità di pianificazione, anche se la copertura degli achievement avanzati resta una sfida aperta.
\end{itemize}

\section{Conclusioni}

L'integrazione dell'Helper e del Reviewer determina benefici significativi in termini di efficienza e stabilità. La configurazione HeRoN risulta superiore per reward medio e consistenza, pur presentando limiti nella copertura degli achievement più avanzati. Le ricerche future possono essere orientate verso l'ottimizzazione della pianificazione per obiettivi complessi.

% --- DQN+Helper: Dashboard multi-metrica ---
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/plots_dqn_helper/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica DQN+Helper. Il confronto mostra miglioramento su tutte le metriche rispetto al DQN Baseline: reward più concentrato, coverage degli achievement più ampio, efficienza temporale superiore.}
\label{fig:multi_metric_dashboard_helper}
\end{figure}

% --- DQN+Helper: Heatmap achievement ---
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_heatmap.png}
\caption{Heatmap della distribuzione degli achievement per DQN+Helper. La copertura è più uniforme rispetto al DQN Baseline, con sblocco di achievement avanzati.}
\label{fig:achievement_heatmap_helper_1}
\end{figure}

% --- DQN+Helper: Scatter efficienza ---
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/efficiency_scatter.png}
\caption{Scatter plot dell'efficienza temporale - DQN+Helper: reward per step vs episodio. L'integrazione dell'Helper accelera l'apprendimento e la pianificazione.}
\label{fig:efficiency_scatter_helper}
\end{figure}

% --- DQN+Helper: Curve di apprendimento per achievement specifici ---
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/collect_wood.png}
\caption{Curve di apprendimento per collect\_wood - DQN+Helper. Plateau raggiunto più rapidamente rispetto al DQN Baseline.}
\label{fig:achievement_curve_helper_wood}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/collect_sapling.png}
\caption{Curve di apprendimento per collect\_sapling - DQN+Helper. Success rate superiore e maggiore stabilità.}
\label{fig:achievement_curve_helper_sapling}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/place_table.png}
\caption{Curve di apprendimento per place\_table - DQN+Helper. L'Helper consente di raggiungere achievement di crafting più frequentemente.}
\label{fig:achievement_curve_helper_table}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/place_plant.png}
\caption{Curve di apprendimento per place\_plant - DQN+Helper. Strategie di farming più efficaci rispetto al baseline.}
\label{fig:achievement_curve_helper_plant}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/defeat_zombie.png}
\caption{Curve di apprendimento per defeat\_zombie - DQN+Helper. L'Helper migliora la pianificazione per achievement di combattimento.}
\label{fig:achievement_curve_helper_zombie}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/collect_drink.png}
\caption{Curve di apprendimento per collect\_drink - DQN+Helper. Gestione risorse vitali appresa più rapidamente.}
\label{fig:achievement_curve_helper_drink}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_helper/achievement_curves/wake_up.png}
\caption{Curve di apprendimento per wake\_up - DQN+Helper. Gestione ciclo giorno/notte più efficace.}
\label{fig:achievement_curve_helper_wake}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/heron/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica HeRoN. Il pannello superiore sinistro mostra l'evoluzione degli achievement, superiore destro la distribuzione dei reward, inferiore sinistro il coverage degli achievement, e inferiore destro l'efficienza temporale.}
\label{fig:multi_metric_dashboard_heron}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{immagini/plots_dqn_BASE/multi_metric_dashboard.png}
\caption{Dashboard multi-metrica DQN Baseline per confronto. Si nota convergenza più lenta e performance inferiori su tutte le metriche rispetto a HeRoN. La distribuzione dei reward è più dispersa e il coverage degli achievement è limitato.}
\label{fig:multi_metric_dashboard_baseline}
\end{figure}

\subsection{Reward Cumulativo - Dettaglio}
Reward medio per episodio (shaped reward):

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Media} & \textbf{Std Dev} & \textbf{Max} \\\hline
DQN Baseline & 7.99 & 2.62 & 14.12 \\\hline
DQN + Helper & 7.86 & 2.31 & 15.8 \\\hline
HeRoN Completo & \textbf{8.33} & \textbf{2.40} & \textbf{16.2} \\\hline
\end{tabular}
\caption{Reward cumulativo per episodio (ultimi 100 episodi)}
\end{table}

\subsection{Analisi della Convergenza}

\subsubsection{Curve di Apprendimento}
Le curve di apprendimento mostrano il numero medio di achievement su finestre di 50 episodi:

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/heron/moving_averages.png}
\caption{Progressione achievement durante training con medie mobili - HeRoN. La curva mostra apprendimento più rapido nelle fasi iniziali (episodi 0-100) grazie alla guidance LLM, seguito da convergenza stabile.}
\label{fig:learning_curve_heron}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{immagini/plots_dqn_BASE/moving_averages.png}
\caption{Progressione achievement durante training con medie mobili - DQN Baseline. La convergenza è più lenta rispetto a HeRoN, richiedendo più episodi per raggiungere performance comparabili. La curva mostra maggiore varianza iniziale.}
\label{fig:learning_curve_baseline}
\end{figure}


\subsubsection{Velocità di Convergenza}
Episodio in cui ciascuna configurazione raggiunge l'80\% del suo score massimo:

\begin{table}[H]
\centering
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Episodio Convergenza} & \textbf{Score 80\%} \\\hline
DQN Baseline & 220 & 2.2 \\\hline
DQN + Helper & 150 & 2.1 \\\hline
HeRoN Completo & \textbf{120} & \textbf{2.2} \\\hline
\end{tabular}
\caption{Velocità di convergenza}
\end{table}

HeRoN converge il \textbf{45\% più velocemente} rispetto al DQN baseline.

\subsection{Analisi del Numero di Azioni per Sequenza}
È stato condotto un esperimento per determinare il numero ottimale di azioni per sequenza Helper.

\textbf{Configurazione Implementata}:
\begin{itemize}
\item \textbf{Min sequence length}: 3 azioni (garantisce minima pianificazione)
\item \textbf{Max sequence length}: 5 azioni (limite superiore per flessibilità)
\item \textbf{Default sequence length}: 4 azioni (target prompt, bilanciato)
\end{itemize}

\textbf{Conclusioni}:
\begin{itemize}
\item 5 azioni è ottimale per bilanciare pianificazione e flessibilità
\item Sequenze troppo corte (1-3) richiedono troppe chiamate LLM
\item Sequenze troppo lunghe (7-10) riducono la capacità di adattamento
\item Configuration range [3-5] permette adattamento dinamico basato su contesto
\end{itemize}

\subsection{Sessioni di Addestramento del NPC}

\subsubsection{Configurazione delle Sessioni di Training}
Il training del sistema HeRoN è stato condotto attraverso multiple sessioni con configurazioni diverse per validare l'efficacia dell'architettura.

\subsubsection{Risultati per Sessione}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Avg Ach} & \textbf{Max Ach} & \textbf{Coverage} & \textbf{Avg Reward} & \textbf{Best Ep} \\\hline
DQN Baseline & 2.74 & 6 & 36.4\% & 7.99 & 171 \\\hline
DQN + Helper & 2.67 & 6 & 50.0\% & 7.86 & 72 \\\hline
HeRoN Completo & 2.80 & 5 & 41.0\% & 8.33 & 127 \\\hline
\end{tabular}
\caption{Performance per configurazione di training (ultimi 100 episodi)}
\end{table}

\textbf{Osservazioni}:
\begin{itemize}
\item \textbf{DQN Baseline}: Reference per confronto, solo DQN
\item \textbf{DQN + Helper}: Prima integrazione LLM, miglioramento rispetto al baseline
\item \textbf{HeRoN Completo}: Sessione principale con Reviewer, migliori performance complessive
\end{itemize}


\subsection{Dimostrazione dell'Abilità del NPC nello Svolgere i Task}

\subsubsection{Performance sui Task Fondamentali}
L'analisi delle metriche di training dimostra che il NPC HeRoN è in grado di completare efficacemente i task fondamentali di Crafter:

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Task Category} & \textbf{HeRoN} & \textbf{DQN Baseline} & \textbf{Miglioramento} \\\hline
Raccolta Risorse & 85.7\% & 26.3\% & +226\% \\\hline
Gestione Sopravvivenza & 59.7\% & 19\% & +214\% \\\hline
Crafting Base & 1\% & 0.7\% & +43\% \\\hline
Crafting Avanzato & 0\% & 0\% & --- \\\hline
Combat & 0\% & 0\% & --- \\\hline
\end{tabular}
\caption{Success rate per categoria di task}
\end{table}
\end{table}

\subsubsection{Progressione Tecnologica}
La capacità del NPC di seguire la catena tecnologica di Crafter è evidenziata dai dati reali di training:

\begin{itemize}
\item \textbf{collect\_sapling}: 257 unlock in 300 episodi (85.7\% success rate)
\item \textbf{collect\_wood}: 79 unlock (26.3\% success rate)
\item \textbf{place\_table}: 3 unlock (1\% success rate) - primo sblocco all'episodio 27
\item \textbf{wake\_up}: 179 unlock (59.7\% success rate) - gestione sleep efficace
\item \textbf{place\_plant}: 199 unlock (66.3\% success rate) - agricoltura funzionale
\end{itemize}

\textbf{Osservazione Critica}: Il NPC mostra capacità eccellenti nei task di base (raccolta, sopravvivenza), ma fatica nei task che richiedono sequenze lunghe (crafting pickaxe, smelting). Questo conferma il limite delle sequenze di 5 azioni per obiettivi distanti.

\subsubsection{Analisi del Numero di Azioni per Sequenza}
L'analisi del numero di azioni per sequenza mostra che:

\begin{itemize}
\item Le sequenze ottimali contengono in media 4 azioni.
\item Sequenze con meno di 3 azioni non garantiscono una pianificazione adeguata.
\item Sequenze con più di 5 azioni mostrano un aumento dei tempi di calcolo senza benefici significativi in termini di performance.
\end{itemize}

\textbf{Conclusione}: La lunghezza della sequenza di 4 azioni è ottimale per bilanciare pianificazione e flessibilità.

\section{Analisi Comparativa Finale}

\subsection{Riepilogo Metriche Chiave}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Achiev. Medio} & \textbf{Coverage} & \textbf{Reward Medio} \\\hline
DQN Baseline & 2.74 & 36.4\% & 7.99 \\\hline
DQN + Helper & 2.67 & 50.0\% & 7.86 \\\hline
HeRoN Completo & \textbf{2.80} & 41.0\% & \textbf{8.33} \\\hline
\end{tabular}
\caption{Riepilogo delle metriche chiave per configurazione}
\end{table}

\subsection{Conclusioni Finali}
I risultati ottenuti confermano che:

\begin{itemize}
	\item L'integrazione dell'Helper e del Reviewer porta a un miglioramento significativo delle performance dell'agente.
	\item HeRoN si distingue come la configurazione più efficace, grazie a una migliore pianificazione e stabilità.
	\item La copertura degli achievement avanzati rimane una sfida, suggerendo direzioni per future ricerche.
\end{itemize}

\textbf{Ricerche Future}: Ottimizzazione della copertura degli achievement avanzati e riduzione del sovraccarico computazionale associato all'uso degli LLM.