\chapter{Risultati Sperimentali}

\section{Introduzione}
In questo capitolo vengono presentati e confrontati i risultati sperimentali delle cinque configurazioni principali: DQN Baseline, DQN+Helper, HeRoN Initial, HeRoN Random e HeRoN Final. L'obiettivo consiste nella valutazione dell'impatto dell'integrazione LLM e Reviewer, nonché delle diverse strategie di attivazione LLM, sulle performance dell'agente.

\section{Configurazioni Testate}
\begin{itemize}
	\item \textbf{DQN Baseline}: Solo Deep Q-Network, senza assistenza LLM. 
	\item \textbf{DQN + Helper}: DQN con Helper LLM che suggerisce sequenze di azioni, senza componente Reviewer.
	\item \textbf{HeRoN Initial}: DQN + Helper + Reviewer con LLM attivo solo nei primi 100 step di ogni episodio.
	\item \textbf{HeRoN Random}: DQN + Helper + Reviewer, con attivazione stocastica. LLM attivo con probabilità casuale del 50\% ad ogni step.
	\item \textbf{HeRoN Final}: DQN + Helper + Reviewer, con probabilità LLM crescente da 0\% a 100\% durante ogni episodio.
\end{itemize}

\section{Confronto tra Configurazioni}

\subsection{Metriche Principali}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metrica} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
Achievement medio & $0.41 \pm 0.90$ & $0.67 \pm 1.18$ & $\mathbf{2.67 \pm 1.09}$ & $1.28 \pm 1.34$ & $0.76 \pm 1.18$ \\
\hline
Coverage & 18.2\% & 27.3\% & \textbf{50.0\%} & \textbf{50.0\%} & 36.4\% \\
 & (4/22) & (6/22) & \textbf{(11/22)} & \textbf{(11/22)} & (8/22) \\
\hline
Reward shaped & $1.86 \pm 1.07$ & $2.93 \pm 1.51$ & $\mathbf{8.02 \pm 2.88}$ & $6.47 \pm 2.30$ & $3.84 \pm 1.66$ \\
\hline
Total unlocks (avg) & 123 & 201 & \textbf{802} & 384 & 228 \\
\hline
\end{tabular}
\caption{Metriche di performance delle cinque configurazioni (1500 episodi training, 5 run × 300).}
\end{table}

\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Run} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
\hline
\multicolumn{6}{|c|}{\textbf{Run 1}} \\
\hline
Ach medio & 0.37 & 0.63 & 2.70 & 1.33 & 0.73 \\
\hline
Reward & 1.97 & 2.80 & 8.17 & 6.45 & 3.73 \\
\hline
Tot unlocks & 111 & 189 & 810 & 400 & 219 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 2}} \\
\hline
Ach medio & 0.49 & 0.70 & 2.68 & 1.16 & 0.70 \\
\hline
Reward & 1.72 & 3.06 & 8.11 & 6.39 & 3.88 \\
\hline
Tot unlocks & 146 & 211 & 804 & 347 & 210 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 3}} \\
\hline
Ach medio & 0.45 & 0.74 & 2.60 & 1.24 & 0.76 \\
\hline
Reward & 1.84 & 2.99 & 7.81 & 6.53 & 3.77 \\
\hline
Tot unlocks & 134 & 223 & 780 & 371 & 228 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 4}} \\
\hline
Ach medio & 0.35 & 0.64 & 2.71 & 1.30 & 0.83 \\
\hline
Reward & 1.95 & 2.92 & 8.20 & 6.36 & 3.90 \\
\hline
Tot unlocks & 105 & 191 & 814 & 389 & 249 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 5}} \\
\hline
Ach medio & 0.40 & 0.64 & 2.67 & 1.38 & 0.78 \\
\hline
Reward & 1.82 & 2.87 & 7.81 & 6.62 & 3.92 \\
\hline
Tot unlocks & 120 & 191 & 801 & 413 & 234 \\
\hline
\end{tabular}
\caption{Metriche dettagliate per ogni run individuale (300 episodi per run).}
\label{tab:run_details}
\end{table}

\subsection{Curve di Apprendimento}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/01_learning_curves.png}
\caption{Curve di apprendimento del reward shaped.}
\label{fig:learning_curves}
\end{figure}

\noindent
\begin{itemize}
	\item \textbf{HeRoN Initial (verde)}: raggiunge il reward più alto (8.02) grazie alla guidance LLM consistente nei primi 100 step.
	\item \textbf{HeRoN Random (viola)}: raggiunge 6.47 con variabilità stocastica.
	\item \textbf{HeRoN Final (rosso)}: presenta performance intermedie (3.84).
	\item \textbf{DQN+Helper (arancione)}: raggiunge 2.93.
	\item \textbf{DQN Baseline (blu)}: raggiunge 1.86.
\end{itemize}
Le varianti HeRoN con Reviewer superano significativamente le configurazioni senza integrazione LLM completa.

\subsection{Dettaglio Achievement per Configurazione}

\textbf{Achievement sbloccati per configurazione}:

\begin{itemize}
    \item \textbf{DQN Baseline (4/22)}: collect\_drink, collect\_wood, eat\_cow, place\_plant
    \item \textbf{DQN+Helper (6/22)}: collect\_drink, defeat\_skeleton, defeat\_zombie, make\_wood\_sword, place\_table, wake\_up
    \item \textbf{HeRoN Initial (11/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_skeleton, defeat\_zombie, eat\_cow, make\_wood\_pickaxe, make\_wood\_sword, place\_plant, place\_table, wake\_up
    \item \textbf{HeRoN Random (11/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_skeleton, defeat\_zombie, eat\_cow, make\_wood\_pickaxe, make\_wood\_sword, place\_plant, place\_table, wake\_up (identico a HeRoN Initial)
    \item \textbf{HeRoN Final (8/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_zombie, eat\_cow, place\_plant, place\_table, wake\_up
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/04_achievement_heatmap.png}
\caption{Matrice achievement sbloccati per configurazione.}
\label{fig:achievement_heatmap}
\end{figure}

\noindent

\subsection{Native vs Shaped Reward}

Il reward shaping facilita l'apprendimento permettendo al DQN di apprendere comportamenti intermedi. Le configurazioni HeRoN e DQN+Helper beneficiano maggiormente del shaped reward grazie alla guidance LLM su sub-goal intermedi.

\vspace{0.3cm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/09_native_vs_shaped_reward.png}
\caption{Native vs shaped reward: confronto segnali.}
\label{fig:native_vs_shaped}
\end{figure}

\noindent

\subsection{Analisi Multi-Metrica}


Come evidenziato nelle tabelle precedenti, HeRoN Initial domina su tutte le metriche: achievement medio (2.67), coverage (50\%), reward (8.02) e unlock totali (802). La Figura \ref{fig:summary_stats} fornisce una visualizzazione multi-metrica complessiva.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/10_summary_statistics.png}
\caption{Analisi multi-metrica delle configurazioni.}
\label{fig:summary_stats}
\end{figure}

\noindent
\textbf{Descrizione:} 
\begin{itemize}
    \item \textbf{Top-left}: Reward medio shaped mostra HeRoN Initial vincitore (8.02), significativamente superiore a tutte le altre configurazioni
    \item \textbf{Top-right}: Achievement totali cumulativi evidenziano HeRoN Initial come leader (802 unlock) seguito da HeRoN Random (384), HeRoN Final (228), DQN+Helper (201) e DQN Baseline (123)
    \item \textbf{Bottom-left}: Lunghezza media episodi (moves) indica capacità di sopravvivenza
    \item \textbf{Bottom-right}: Achievement unici (su 22 possibili) conferma coverage massima di HeRoN Initial e HeRoN Random (11/22, 50\%)
\end{itemize}
\vspace{0.5cm}

\section{Risultati Testing}

Dopo il training, i modelli sono stati testati per 1500 episodi complessivi (5 run da 300 episodi ciascuna) per valutare la generalizzazione e la robustezza. Tutte le configurazioni sono state testate senza LLM attivo, utilizzando solo la policy appresa.

\subsection{Metriche di Testing}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metrica} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
Achievement medio & $0.25 \pm 0.47$ & $0.31 \pm 0.53$ & $0.76 \pm 0.83$ & $\mathbf{0.80 \pm 0.84}$ & $0.46 \pm 0.63$ \\
\hline
Coverage & 36.4\% & 45.5\% & \textbf{50.0\%} & \textbf{50.0\%} & \textbf{50.0\%} \\
 & (8/22) & (10/22) & \textbf{(11/22)} & \textbf{(11/22)} & \textbf{(11/22)} \\
\hline
Reward shaped & $1.18 \pm 0.72$ & $2.38 \pm 1.00$ & $\mathbf{5.21 \pm 1.67}$ & $5.02 \pm 1.71$ & $2.98 \pm 1.11$ \\
\hline
Total unlocks (avg) & 75 & 93 & 228 & \textbf{240} & 138 \\
\hline
\end{tabular}
\caption{Metriche di testing delle cinque configurazioni (1500 episodi totali, senza LLM).}
\end{table}

\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Run} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
\hline
\multicolumn{6}{|c|}{\textbf{Run 1}} \\
\hline
Ach medio & 0.23 & 0.27 & 0.76 & 0.74 & 0.46 \\
\hline
Reward & 1.23 & 2.41 & 5.21 & 4.96 & 2.94 \\
\hline
Tot unlocks & 68 & 81 & 228 & 223 & 138 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 2}} \\
\hline
Ach medio & 0.23 & 0.30 & 0.76 & 0.79 & 0.44 \\
\hline
Reward & 1.18 & 2.41 & 5.16 & 5.10 & 2.98 \\
\hline
Tot unlocks & 69 & 90 & 228 & 238 & 133 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 3}} \\
\hline
Ach medio & 0.26 & 0.30 & 0.72 & 0.85 & 0.50 \\
\hline
Reward & 1.18 & 2.35 & 5.17 & 5.05 & 3.03 \\
\hline
Tot unlocks & 78 & 91 & 215 & 255 & 150 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 4}} \\
\hline
Ach medio & 0.26 & 0.35 & 0.75 & 0.74 & 0.44 \\
\hline
Reward & 1.15 & 2.36 & 5.21 & 5.07 & 2.96 \\
\hline
Tot unlocks & 77 & 104 & 224 & 221 & 131 \\
\hline
\multicolumn{6}{|c|}{\textbf{Run 5}} \\
\hline
Ach medio & 0.28 & 0.33 & 0.82 & 0.87 & 0.46 \\
\hline
Reward & 1.15 & 2.37 & 5.31 & 4.92 & 2.99 \\
\hline
Tot unlocks & 84 & 98 & 246 & 262 & 137 \\
\hline
\end{tabular}
\caption{Metriche di testing dettagliate per ogni run individuale (300 episodi per run, senza LLM).}
\label{tab:test_run_details}
\end{table}

\noindent
Le configurazioni HeRoN mantengono il vantaggio acquisito in training anche in fase di testing. Le tre varianti HeRoN raggiungono tutte la massima coverage (50.0\%, 11/22 achievement), mentre DQN Base e DQN+Helper si fermano rispettivamente a 36.4\% (8/22) e 45.5\% (10/22). HeRoN Random ottiene il maggior numero medio di unlock per run (240), seguito da HeRoN Initial (228), mentre HeRoN Initial mantiene il reward shaped più alto (5.21). Tutte le varianti HeRoN superano significativamente DQN baseline.

\subsection{Visualizzazioni Testing}


\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/testing/02_achievements_bar.png}
\caption{Achievement totali sbloccati in testing.}
\label{fig:test_achievements_bar}
\end{figure}

\noindent
\textbf{Descrizione}: Tutte le varianti HeRoN sbloccano 11 achievement unici (50.0\% coverage), dimostrando una capacità esplorativa superiore rispetto a DQN+Helper (10/22) e DQN Base (8/22). Per quanto riguarda il numero medio di unlock per run (300 episodi), HeRoN Random raggiunge il valore massimo (240), seguito da HeRoN Initial (228), HeRoN Final (138), DQN+Helper (94) e DQN Base (75), confermando la maggiore capacità esplorativa delle varianti HeRoN anche in testing senza LLM attivo.

\subsection{Confronto Training vs Testing}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Reward Train} & \textbf{Reward Test} & \textbf{Cover. Train} & \textbf{Cover. Test} \\
\hline
DQN Baseline & 1.86 & 1.18 & 18.2\% & 36.4\% \\
\hline
DQN + Helper & 2.93 & 2.38 & 27.3\% & 45.5\% \\
\hline
\textbf{HeRoN Initial} & \textbf{8.02} & \textbf{5.21} & \textbf{50.0\%} & \textbf{50.0\%} \\
\hline
HeRoN Random & 6.47 & 5.02 & 50.0\% & 50.0\% \\
\hline
HeRoN Final & 3.84 & 2.98 & 36.4\% & 50.0\% \\
\hline
\end{tabular}
\caption{Confronto performance training vs testing.}
\end{table}

\noindent
I risultati di testing mostrano una stabilità eccellente delle policy apprese. Le varianti HeRoN mantengono o migliorano la coverage raggiunta in training: HeRoN Initial e Random mantengono entrambi 50.0\%, mentre HeRoN Final migliora da 36.4\% a 50.0\%. Questo dimostra che la guidance LLM durante training ha permesso di apprendere policy robuste che generalizzano efficacemente anche senza LLM in inference. Il reward decresce leggermente per l'assenza di LLM, ma le proporzioni relative restano invariate, con HeRoN Initial che mantiene il vantaggio su tutte le configurazioni.

\subsection{Conclusioni Testing}

I risultati di testing confermano pienamente l'efficacia dell'architettura HeRoN: la policy appresa durante training con guidance LLM mantiene performance superiori anche senza LLM in inference. Tutte e tre le varianti HeRoN raggiungono la massima coverage (50.0\%, 11/22 achievement), dimostrando robustezza e capacità di generalizzazione eccellenti. HeRoN Initial mantiene il vantaggio su reward shaped (5.21), mentre HeRoN Random eccelle nel numero medio di unlock per run (240 vs 228 di HeRoN Initial). La stabilità delle metriche tra training e testing evidenzia che la guidance LLM non introduce dipendenze critiche in inference, ma permette di apprendere policy più esplorative e robuste che generalizzano efficacemente.
