\chapter{Risultati Sperimentali}

\section{Introduzione}
In questo capitolo vengono presentati e confrontati i risultati sperimentali delle cinque configurazioni principali: DQN Baseline, DQN+Helper, HeRoN Initial, HeRoN Random e HeRoN Final. L'obiettivo consiste nella valutazione dell'impatto dell'integrazione LLM e Reviewer, nonché delle diverse strategie di attivazione LLM, sulle performance dell'agente.

\section{Configurazioni Testate}
\begin{itemize}
	\item \textbf{DQN Baseline}: Solo Deep Q-Network, senza assistenza LLM. 
	\item \textbf{DQN + Helper}: DQN con Helper LLM che suggerisce sequenze di azioni, senza componente Reviewer.
	\item \textbf{HeRoN Initial}: DQN + Helper + Reviewer con LLM attivo solo nei primi 100 step di ogni episodio.
	\item \textbf{HeRoN Random}: DQN + Helper + Reviewer, con attivazione stocastica. LLM attivo con probabilità casuale del 50\% ad ogni step.
	\item \textbf{HeRoN Final}: DQN + Helper + Reviewer, con probabilità LLM crescente da 0\% a 100\% durante ogni episodio.
\end{itemize}

\section{Confronto tra Configurazioni}

\subsection{Metriche Principali}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metrica} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
Achievement medio & 0.41 & 0.67 & \textbf{2.65} & 1.28 & 0.76 \\
\hline
Coverage & 18.2\% & 27.3\% & \textbf{50.0\%} & \textbf{50.0\%} & 36.4\% \\
 & (4/22) & (6/22) & \textbf{(11/22)} & \textbf{(11/22)} & (8/22) \\
\hline
Reward shaped & 1.86 & 2.93 & \textbf{8.02} & 6.47 & 3.84 \\
\hline
Total unlocks & 123 & 200 & \textbf{802} & 385 & 228 \\
\hline
\end{tabular}
\caption{Metriche di performance delle cinque configurazioni (300 episodi training).}
\end{table}

\subsection{Curve di Apprendimento}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/01_learning_curves.png}
\caption{Curve di apprendimento del reward shaped.}
\label{fig:learning_curves}
\end{figure}

\noindent
\begin{itemize}
	\item \textbf{HeRoN Initial (verde)}: raggiunge il reward più alto (8.02) grazie alla guidance LLM consistente nei primi 100 step.
	\item \textbf{HeRoN Random (viola)}: raggiunge 6.47 con variabilità stocastica.
	\item \textbf{HeRoN Final (rosso)}: presenta performance intermedie (3.84).
	\item \textbf{DQN+Helper (arancione)}: raggiunge 2.93.
	\item \textbf{DQN Baseline (blu)}: raggiunge 1.86.
\end{itemize}
Le varianti HeRoN con Reviewer superano significativamente le configurazioni senza integrazione LLM completa.

\subsection{Dettaglio Achievement per Configurazione}

\textbf{Achievement sbloccati per configurazione}:

\begin{itemize}
    \item \textbf{DQN Baseline (4/22)}: collect\_drink, collect\_wood, eat\_cow, place\_plant
    \item \textbf{DQN+Helper (6/22)}: collect\_drink, defeat\_skeleton, defeat\_zombie, make\_wood\_sword, place\_table, wake\_up
    \item \textbf{HeRoN Initial (11/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_skeleton, defeat\_zombie, eat\_cow, make\_wood\_pickaxe, make\_wood\_sword, place\_plant, place\_table, wake\_up
    \item \textbf{HeRoN Random (11/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_skeleton, defeat\_zombie, eat\_cow, make\_wood\_pickaxe, make\_wood\_sword, place\_plant, place\_table, wake\_up (identico a HeRoN Initial)
    \item \textbf{HeRoN Final (8/22)}: collect\_drink, collect\_sapling, collect\_wood, defeat\_zombie, eat\_cow, place\_plant, place\_table, wake\_up
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/04_achievement_heatmap.png}
\caption{Matrice achievement sbloccati per configurazione.}
\label{fig:achievement_heatmap}
\end{figure}

\noindent

\subsection{Native vs Shaped Reward}

Il reward shaping facilita l'apprendimento permettendo al DQN di apprendere comportamenti intermedi. Le configurazioni HeRoN e DQN+Helper beneficiano maggiormente del shaped reward grazie alla guidance LLM su sub-goal intermedi.

\vspace{0.3cm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/09_native_vs_shaped_reward.png}
\caption{Native vs shaped reward: confronto segnali.}
\label{fig:native_vs_shaped}
\end{figure}

\noindent

\subsection{Analisi Multi-Metrica}


Come evidenziato nelle tabelle precedenti, HeRoN Initial domina su tutte le metriche: achievement medio (2.65), coverage (50\%), reward (8.02) e unlock totali (802). La Figura \ref{fig:summary_stats} fornisce una visualizzazione multi-metrica complessiva.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/training/10_summary_statistics.png}
\caption{Analisi multi-metrica delle configurazioni.}
\label{fig:summary_stats}
\end{figure}

\noindent
\textbf{Descrizione:} 
\begin{itemize}
    \item \textbf{Top-left}: Reward medio shaped mostra HeRoN Initial vincitore (8.02), significativamente superiore a tutte le altre configurazioni
    \item \textbf{Top-right}: Achievement totali cumulativi evidenziano HeRoN Initial come leader (802 unlock) seguito da HeRoN Random (385), HeRoN Final (228), DQN+Helper (200) e DQN Baseline (123)
    \item \textbf{Bottom-left}: Lunghezza media episodi (moves) indica capacità di sopravvivenza
    \item \textbf{Bottom-right}: Achievement unici (su 22 possibili) conferma coverage massima di HeRoN Initial e HeRoN Random (11/22, 50\%)
\end{itemize}
\vspace{0.5cm}

\section{Risultati Testing}

Dopo il training, i modelli sono stati testati per 300 episodi su nuovi seed per valutare la generalizzazione. Tutte le configurazioni sono state testate senza LLM attivo, utilizzando solo la policy appresa.

\subsection{Metriche di Testing}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Metrica} & \textbf{DQN} & \textbf{DQN+H} & \textbf{HeRoN I} & \textbf{HeRoN R} & \textbf{HeRoN F} \\
\hline
Achievement medio & $0.25 \pm 0.64$ & $0.31 \pm 0.76$ & $0.76 \pm 0.96$ & $\mathbf{0.80 \pm 0.96}$ & $0.46 \pm 0.78$ \\
\hline
Coverage & 13.6\% & 22.7\% & \textbf{40.9\%} & 36.4\% & 31.8\% \\
 & (3/22) & (5/22) & \textbf{(9/22)} & (8/22) & (7/22) \\
\hline
Reward shaped & $1.18 \pm 0.72$ & $2.38 \pm 1.00$ & $\mathbf{5.21 \pm 1.67}$ & $5.02 \pm 1.71$ & $2.98 \pm 1.11$ \\
\hline
Total unlocks & 76 & 94 & 228 & \textbf{239} & 138 \\
\hline
\end{tabular}
\caption{Metriche di testing delle cinque configurazioni (300 episodi, senza LLM).}
\end{table}

\noindent
Le configurazioni HeRoN mantengono il vantaggio acquisito in training anche in fase di testing. HeRoN Initial raggiunge la coverage massima nel testing (40.9\%, 9/22), superando HeRoN Random (36.4\%, 8/22). HeRoN Random ottiene il maggior numero medio di achievement (0.80), mentre HeRoN Initial ha reward shaped leggermente più alto (5.21 vs 5.02). Tutte le varianti HeRoN superano significativamente DQN baseline.

\subsection{Visualizzazioni Testing}


\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/testing/02_achievements_bar.png}
\caption{Achievement totali sbloccati in testing.}
\label{fig:test_achievements_bar}
\end{figure}

\noindent
\textbf{Descrizione}: HeRoN Initial sblocca 9 achievement unici, superando HeRoN Random (8/22) e HeRoN Final (7/22). DQN Baseline rimane limitato a 3 achievement base. Per quanto riguarda il numero totale di istanze di unlock, HeRoN Random raggiunge il valore massimo (239), seguito da HeRoN Initial (228), HeRoN Final (138), DQN+Helper (94) e DQN Base (76), confermando la maggiore capacità esplorativa delle varianti HeRoN.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{../grafici/testing/03_achievement_radar.png}
\caption{Radar chart achievement testing.}
\label{fig:test_achievement_radar}
\end{figure}

\noindent
\textbf{Descrizione:} Visualizzazione radar delle categorie di achievement: le varianti HeRoN coprono più categorie (collect, combat, crafting, survive) rispetto a DQN Baseline limitato a collect e survive.

\subsection{Confronto Training vs Testing}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\rowcolor{gray!20}
\textbf{Configurazione} & \textbf{Reward Train} & \textbf{Reward Test} & \textbf{Cover. Train} & \textbf{Cover. Test} \\
\hline
DQN Baseline & 1.86 & 1.18 & 18.2\% & 13.6\% \\
\hline
DQN + Helper & 2.93 & 2.38 & 27.3\% & 22.7\% \\
\hline
\textbf{HeRoN Initial} & \textbf{8.02} & \textbf{5.21} & \textbf{50.0\%} & \textbf{40.9\%} \\
\hline
HeRoN Random & 6.47 & 5.02 & 50.0\% & 36.4\% \\
\hline
HeRoN Final & 3.84 & 2.98 & 36.4\% & 31.8\% \\
\hline
\end{tabular}
\caption{Confronto performance training vs testing.}
\end{table}

\noindent
La coverage decresce leggermente in testing rispetto al training, riflettendo il fatto che senza LLM attivo gli agenti hanno difficoltà a mantenere le stesse performance esplorative. HeRoN Initial rimane il leader (40.9\% vs 50.0\% nel training), confermando la superiorità della sua strategia anche in inference. Il reward decresce leggermente (assenza di LLM e nuovi seed), ma le proporzioni relative restano invariate.

\subsection{Conclusioni Testing}

I risultati confermano l'efficacia dell'architettura HeRoN: la policy appresa durante training con guidance LLM mantiene performance superiori anche senza LLM in inference. HeRoN Initial mantiene il vantaggio su tutte le metriche. La riduzione di coverage in testing riflette la difficoltà maggiore senza LLM, confermando l'importanza della guidance LLM per l'esplorazione efficace.
